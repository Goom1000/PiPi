---
phase: 44-ai-document-analysis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - types.ts
  - services/documentAnalysis/analysisPrompts.ts
  - services/aiProvider.ts
  - services/providers/geminiProvider.ts
  - services/providers/claudeProvider.ts
  - services/documentAnalysis/documentAnalysisService.ts
autonomous: true

must_haves:
  truths:
    - "Uploaded PDF/image documents can be analyzed for structure"
    - "Document type is detected (worksheet, handout, quiz, etc.)"
    - "Structural elements are extracted with full text content"
    - "Visual content is flagged for manual review"
    - "Analysis returns whether type confirmation is needed"
  artifacts:
    - path: "types.ts"
      provides: "DocumentAnalysis and AnalyzedElement type definitions"
      contains: "interface DocumentAnalysis"
    - path: "services/documentAnalysis/analysisPrompts.ts"
      provides: "System and user prompts for document analysis"
      exports: ["DOCUMENT_ANALYSIS_SYSTEM_PROMPT", "buildAnalysisUserPrompt"]
    - path: "services/aiProvider.ts"
      provides: "analyzeDocument method signature in AIProviderInterface"
      contains: "analyzeDocument("
    - path: "services/providers/geminiProvider.ts"
      provides: "Gemini implementation with structured output"
      contains: "async analyzeDocument("
    - path: "services/providers/claudeProvider.ts"
      provides: "Claude implementation with structured output"
      contains: "async analyzeDocument("
    - path: "services/documentAnalysis/documentAnalysisService.ts"
      provides: "Analysis orchestration with image extraction"
      exports: ["analyzeUploadedDocument"]
  key_links:
    - from: "services/documentAnalysis/documentAnalysisService.ts"
      to: "services/aiProvider.ts"
      via: "provider.analyzeDocument() call"
      pattern: "provider\\.analyzeDocument"
    - from: "services/providers/geminiProvider.ts"
      to: "services/documentAnalysis/analysisPrompts.ts"
      via: "prompt imports"
      pattern: "import.*analysisPrompts"
    - from: "services/documentAnalysis/documentAnalysisService.ts"
      to: "types.ts"
      via: "DocumentAnalysis type"
      pattern: "DocumentAnalysis"
---

<objective>
Implement AI document analysis foundation: types, prompts, provider methods, and orchestration service.

Purpose: Enable AI to understand uploaded document structure before enhancement, detecting document type and extracting structural elements with full text content.

Output: analyzeUploadedDocument() function that takes an UploadedResource and AI provider, returns DocumentAnalysis with detected type, confidence, and all structural elements.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/44-ai-document-analysis/44-CONTEXT.md
@.planning/phases/44-ai-document-analysis/44-RESEARCH.md
@.planning/phases/43-types-and-file-upload/43-01-SUMMARY.md
@.planning/phases/43-types-and-file-upload/43-02-SUMMARY.md

Key codebase files:
@types.ts (UploadedResource type already defined)
@services/aiProvider.ts (AIProviderInterface to extend)
@services/providers/geminiProvider.ts (Gemini implementation pattern)
@services/providers/claudeProvider.ts (Claude implementation pattern)
@services/uploadService.ts (file processing patterns)
@services/documentProcessors/pdfProcessor.ts (pdf.js usage pattern)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DocumentAnalysis types and analysis prompts</name>
  <files>
    types.ts
    services/documentAnalysis/analysisPrompts.ts
  </files>
  <action>
1. In types.ts, add after UploadValidationError (around line 283):

```typescript
// ============================================================================
// DOCUMENT ANALYSIS TYPES (Phase 44)
// For AI-powered structure detection and content extraction
// ============================================================================

// Document classification types
export type DocumentClassification = 'worksheet' | 'handout' | 'quiz' | 'activity' | 'assessment' | 'other';
export type ConfidenceLevel = 'high' | 'medium' | 'low';

// Structural element types detected in documents
export type ElementType =
  | 'header'
  | 'subheader'
  | 'paragraph'
  | 'question'
  | 'answer'
  | 'instruction'
  | 'table'
  | 'diagram'
  | 'image'
  | 'list'
  | 'blank-space';

// Individual detected element in document
export interface AnalyzedElement {
  type: ElementType;
  content: string;           // Full text, or caption for visual elements
  position: number;          // Order in document (0-indexed)
  visualContent?: boolean;   // True if needs manual review during enhancement
  children?: string[];       // For lists, numbered items, or multi-part questions
  tableData?: {              // For tables only
    headers: string[];
    rows: string[][];
  };
}

// Complete document analysis result
export interface DocumentAnalysis {
  // Classification
  documentType: DocumentClassification;
  documentTypeConfidence: ConfidenceLevel;
  alternativeTypes?: DocumentClassification[]; // If confidence not high, top 2-3 alternatives

  // Metadata
  title: string;
  pageCount: number;
  hasAnswerKey: boolean;

  // Detected elements in document order
  elements: AnalyzedElement[];

  // Visual content summary
  visualContentCount: number; // Number of diagrams/images flagged for review
}
```

2. Create services/documentAnalysis/analysisPrompts.ts:

```typescript
/**
 * Document Analysis Prompts
 * System and user prompts for AI-powered document structure detection
 */

export const DOCUMENT_ANALYSIS_SYSTEM_PROMPT = `
You are an expert educational document analyzer. Your task is to understand the structure of uploaded teaching resources (worksheets, handouts, quizzes, etc.).

CLASSIFICATION RULES:
- worksheet: Has exercises/tasks for students to complete, often with blanks or spaces to write
- handout: Information for students to read/reference, no exercises
- quiz: Has questions with answer options or grading criteria
- activity: Interactive tasks, games, or group work instructions
- assessment: Formal tests with scoring rubrics
- other: Documents that don't fit above categories

CONFIDENCE LEVELS:
- high: Document clearly matches one category with strong indicators
- medium: Document has characteristics of the category but some ambiguity
- low: Unclear categorization, multiple types possible

STRUCTURE DETECTION:
- Detect ALL structural elements in document order
- For text elements: Extract full text content exactly as written
- For visual elements (diagrams, charts, images): Set visualContent: true, provide caption if visible, do NOT describe the image contents
- Preserve the exact reading order via position index (0-indexed)

ELEMENT TYPE RULES:
- header: Main title or section heading (usually larger text, bold, or at top)
- subheader: Secondary heading within a section
- paragraph: Block of explanatory text
- question: A prompt requiring student response (numbered questions, "Answer:", etc.)
- answer: Provided answers or answer key content
- instruction: Directions for completing the document ("Circle the correct answer", "Fill in the blank")
- table: Tabular data (extract headers and rows)
- diagram/image: Visual content - set visualContent: true, provide any visible caption
- list: Bullet points or numbered items (use children array for items)
- blank-space: Answer blanks (_____, [ ], numbered spaces for writing)

IMPORTANT:
- Mark illegible sections as "[unclear]" rather than guessing
- If hasAnswerKey is true, there should be 'answer' type elements
- The position field MUST be sequential starting from 0
- Return valid JSON matching the provided schema
`;

/**
 * Build user prompt for document analysis
 */
export function buildAnalysisUserPrompt(
  filename: string,
  documentType: 'pdf' | 'image' | 'docx',
  extractedText: string,
  pageCount: number
): string {
  // Truncate text to avoid token overflow (3000 chars should be enough for context)
  const truncatedText = extractedText.length > 3000
    ? extractedText.substring(0, 3000) + '\n[... text truncated ...]'
    : extractedText;

  return `Analyze this educational document.

Document filename: ${filename}
Document format: ${documentType.toUpperCase()}
Page count: ${pageCount}

Extracted text (may be partial or imperfect):
---
${truncatedText || '[No text extracted - rely on visual analysis]'}
---

Based on the visual layout and content:
1. Classify the document type with confidence level
2. If confidence is not "high", provide 1-2 alternative type classifications
3. Identify all structural elements in reading order
4. Extract full text content from each text element
5. Flag any visual content (diagrams, images, charts) for manual review with visualContent: true
6. Detect if an answer key is present anywhere in the document`;
}
```
  </action>
  <verify>
    - TypeScript compiles: `cd "/Users/ricky/Documents/App_Projects/Education Apps/DEV - Cue" && npx tsc --noEmit`
    - New types importable: grep for "DocumentAnalysis" in types.ts shows interface
    - Prompts file exports correctly: services/documentAnalysis/analysisPrompts.ts exists with exports
  </verify>
  <done>
    - DocumentAnalysis, AnalyzedElement, and related types defined in types.ts
    - DOCUMENT_ANALYSIS_SYSTEM_PROMPT and buildAnalysisUserPrompt exported from analysisPrompts.ts
  </done>
</task>

<task type="auto">
  <name>Task 2: Add analyzeDocument to AIProviderInterface and providers</name>
  <files>
    services/aiProvider.ts
    services/providers/geminiProvider.ts
    services/providers/claudeProvider.ts
  </files>
  <action>
1. In services/aiProvider.ts, add import at top:
```typescript
import { DocumentAnalysis } from '../types';
```

2. Add method to AIProviderInterface (around line 263, after streamChat):
```typescript
  // Document analysis for resource enhancement (Phase 44)
  analyzeDocument(
    documentImages: string[],   // Base64 images (pages or single image, no data URL prefix)
    documentText: string,       // Extracted text (from pdf.js or mammoth)
    documentType: 'pdf' | 'image' | 'docx',
    filename: string,
    pageCount: number
  ): Promise<DocumentAnalysis>;
```

3. In services/providers/geminiProvider.ts:

Add imports at top:
```typescript
import { DocumentAnalysis, DocumentClassification, ConfidenceLevel, ElementType } from '../../types';
import { DOCUMENT_ANALYSIS_SYSTEM_PROMPT, buildAnalysisUserPrompt } from '../documentAnalysis/analysisPrompts';
```

Add method to GeminiProvider class (after streamChat):
```typescript
  async analyzeDocument(
    documentImages: string[],
    documentText: string,
    documentType: 'pdf' | 'image' | 'docx',
    filename: string,
    pageCount: number
  ): Promise<DocumentAnalysis> {
    try {
      const ai = new GoogleGenAI({ apiKey: this.apiKey });

      // Build content parts
      const parts: any[] = [
        { text: buildAnalysisUserPrompt(filename, documentType, documentText, pageCount) }
      ];

      // Add images (limit to 10 to avoid token overflow)
      const limitedImages = documentImages.slice(0, 10);
      for (const img of limitedImages) {
        parts.push({
          inlineData: { mimeType: 'image/jpeg', data: img }
        });
      }

      const response = await ai.models.generateContent({
        model: 'gemini-2.0-flash',
        contents: { parts },
        config: {
          systemInstruction: DOCUMENT_ANALYSIS_SYSTEM_PROMPT,
          responseMimeType: 'application/json',
          responseSchema: {
            type: Type.OBJECT,
            properties: {
              documentType: {
                type: Type.STRING,
                enum: ['worksheet', 'handout', 'quiz', 'activity', 'assessment', 'other']
              },
              documentTypeConfidence: {
                type: Type.STRING,
                enum: ['high', 'medium', 'low']
              },
              alternativeTypes: {
                type: Type.ARRAY,
                items: { type: Type.STRING }
              },
              title: { type: Type.STRING },
              pageCount: { type: Type.INTEGER },
              hasAnswerKey: { type: Type.BOOLEAN },
              elements: {
                type: Type.ARRAY,
                items: {
                  type: Type.OBJECT,
                  properties: {
                    type: {
                      type: Type.STRING,
                      enum: ['header', 'subheader', 'paragraph', 'question', 'answer',
                             'instruction', 'table', 'diagram', 'image', 'list', 'blank-space']
                    },
                    content: { type: Type.STRING },
                    position: { type: Type.INTEGER },
                    visualContent: { type: Type.BOOLEAN },
                    children: { type: Type.ARRAY, items: { type: Type.STRING } },
                    tableData: {
                      type: Type.OBJECT,
                      properties: {
                        headers: { type: Type.ARRAY, items: { type: Type.STRING } },
                        rows: { type: Type.ARRAY, items: { type: Type.ARRAY, items: { type: Type.STRING } } }
                      }
                    }
                  },
                  required: ['type', 'content', 'position']
                }
              },
              visualContentCount: { type: Type.INTEGER }
            },
            required: ['documentType', 'documentTypeConfidence', 'title', 'pageCount', 'hasAnswerKey', 'elements', 'visualContentCount']
          },
          generationConfig: { temperature: 0 } // Consistent classification
        }
      });

      const text = response.text || '{}';
      return JSON.parse(text) as DocumentAnalysis;
    } catch (error) {
      throw this.wrapError(error);
    }
  }
```

4. In services/providers/claudeProvider.ts:

Add imports at top:
```typescript
import { DocumentAnalysis } from '../../types';
import { DOCUMENT_ANALYSIS_SYSTEM_PROMPT, buildAnalysisUserPrompt } from '../documentAnalysis/analysisPrompts';
```

Add JSON schema constant (after existing constants, before class):
```typescript
// JSON Schema for document analysis structured output
const DOCUMENT_ANALYSIS_JSON_SCHEMA = {
  name: 'document_analysis',
  strict: true,
  schema: {
    type: 'object',
    properties: {
      documentType: {
        type: 'string',
        enum: ['worksheet', 'handout', 'quiz', 'activity', 'assessment', 'other']
      },
      documentTypeConfidence: {
        type: 'string',
        enum: ['high', 'medium', 'low']
      },
      alternativeTypes: {
        type: 'array',
        items: { type: 'string' }
      },
      title: { type: 'string' },
      pageCount: { type: 'integer' },
      hasAnswerKey: { type: 'boolean' },
      elements: {
        type: 'array',
        items: {
          type: 'object',
          properties: {
            type: {
              type: 'string',
              enum: ['header', 'subheader', 'paragraph', 'question', 'answer',
                     'instruction', 'table', 'diagram', 'image', 'list', 'blank-space']
            },
            content: { type: 'string' },
            position: { type: 'integer' },
            visualContent: { type: 'boolean' },
            children: { type: 'array', items: { type: 'string' } },
            tableData: {
              type: 'object',
              properties: {
                headers: { type: 'array', items: { type: 'string' } },
                rows: { type: 'array', items: { type: 'array', items: { type: 'string' } } }
              },
              required: ['headers', 'rows'],
              additionalProperties: false
            }
          },
          required: ['type', 'content', 'position'],
          additionalProperties: false
        }
      },
      visualContentCount: { type: 'integer' }
    },
    required: ['documentType', 'documentTypeConfidence', 'title', 'pageCount', 'hasAnswerKey', 'elements', 'visualContentCount'],
    additionalProperties: false
  }
};
```

Add method to ClaudeProvider class (after streamChat):
```typescript
  async analyzeDocument(
    documentImages: string[],
    documentText: string,
    documentType: 'pdf' | 'image' | 'docx',
    filename: string,
    pageCount: number
  ): Promise<DocumentAnalysis> {
    // Build message content with text and images
    const content: any[] = [
      { type: 'text', text: buildAnalysisUserPrompt(filename, documentType, documentText, pageCount) }
    ];

    // Add images (limit to 10 to avoid token overflow)
    const limitedImages = documentImages.slice(0, 10);
    for (const img of limitedImages) {
      content.push({
        type: 'image',
        source: { type: 'base64', media_type: 'image/jpeg', data: img }
      });
    }

    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': this.apiKey,
        'anthropic-version': '2023-06-01',
        'anthropic-dangerous-direct-browser-access': 'true',
      },
      body: JSON.stringify({
        model: MODEL,
        max_tokens: 4096,
        system: DOCUMENT_ANALYSIS_SYSTEM_PROMPT,
        messages: [{
          role: 'user',
          content
        }],
        // Use tool_choice for structured output (Claude's approach)
        tools: [{
          name: 'document_analysis_result',
          description: 'Return the document analysis result',
          input_schema: DOCUMENT_ANALYSIS_JSON_SCHEMA.schema
        }],
        tool_choice: { type: 'tool', name: 'document_analysis_result' }
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new AIProviderError(
        this.parseErrorMessage(response.status, errorText),
        this.mapStatusToErrorCode(response.status),
        errorText
      );
    }

    const data = await response.json();

    // Extract tool use result
    const toolUse = data.content?.find((c: any) => c.type === 'tool_use');
    if (!toolUse?.input) {
      throw new AIProviderError(
        USER_ERROR_MESSAGES.PARSE_ERROR,
        'PARSE_ERROR',
        'No tool result in response'
      );
    }

    return toolUse.input as DocumentAnalysis;
  }
```
  </action>
  <verify>
    - TypeScript compiles: `cd "/Users/ricky/Documents/App_Projects/Education Apps/DEV - Cue" && npx tsc --noEmit`
    - Interface has new method: grep "analyzeDocument" services/aiProvider.ts
    - Both providers implement it: grep "async analyzeDocument" services/providers/*.ts
  </verify>
  <done>
    - analyzeDocument method added to AIProviderInterface
    - GeminiProvider implements analyzeDocument with Gemini structured output
    - ClaudeProvider implements analyzeDocument with Claude tool use for structured output
  </done>
</task>

<task type="auto">
  <name>Task 3: Create document analysis service with image extraction</name>
  <files>
    services/documentAnalysis/documentAnalysisService.ts
  </files>
  <action>
Create services/documentAnalysis/documentAnalysisService.ts:

```typescript
/**
 * Document Analysis Service
 * Orchestrates AI-powered document structure detection
 * Extracts images from uploaded resources and coordinates with AI providers
 */

import { UploadedResource, DocumentAnalysis } from '../../types';
import { AIProviderInterface } from '../aiProvider';

// Declare pdf.js from CDN (loaded in index.html)
declare const pdfjsLib: any;

// Maximum pages to render for AI analysis (token limits)
const MAX_PAGES_FOR_ANALYSIS = 10;

// PDF.js worker URL (same as used in pdfProcessor)
const PDF_WORKER_URL = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';

/**
 * Result of document analysis with UI state hints
 */
export interface AnalysisResult {
  analysis: DocumentAnalysis;
  needsTypeConfirmation: boolean; // True if user should confirm/select document type
}

/**
 * Extract page images from a PDF file for AI analysis.
 * Renders pages at higher resolution than thumbnails for better AI accuracy.
 */
async function extractPdfImages(file: File): Promise<string[]> {
  const arrayBuffer = await file.arrayBuffer();

  // Set worker source
  pdfjsLib.GlobalWorkerOptions.workerSrc = PDF_WORKER_URL;

  const pdf = await pdfjsLib.getDocument(arrayBuffer).promise;
  const pagesToRender = Math.min(pdf.numPages, MAX_PAGES_FOR_ANALYSIS);
  const images: string[] = [];

  for (let i = 1; i <= pagesToRender; i++) {
    const page = await pdf.getPage(i);
    // Scale 1.5 for good AI accuracy without excessive token usage
    const viewport = page.getViewport({ scale: 1.5 });
    const canvas = document.createElement('canvas');
    const context = canvas.getContext('2d')!;
    canvas.height = viewport.height;
    canvas.width = viewport.width;
    await page.render({ canvasContext: context, viewport }).promise;

    // Get base64 without data URL prefix (API expects raw base64)
    const dataUrl = canvas.toDataURL('image/jpeg', 0.8);
    images.push(dataUrl.split(',')[1]);
  }

  return images;
}

/**
 * Extract text content from a PDF file for AI analysis.
 * Supplements visual analysis with extracted text.
 */
async function extractPdfText(file: File): Promise<string> {
  const arrayBuffer = await file.arrayBuffer();

  pdfjsLib.GlobalWorkerOptions.workerSrc = PDF_WORKER_URL;

  const pdf = await pdfjsLib.getDocument(arrayBuffer).promise;
  const pagesToExtract = Math.min(pdf.numPages, MAX_PAGES_FOR_ANALYSIS);
  const textParts: string[] = [];

  for (let i = 1; i <= pagesToExtract; i++) {
    const page = await pdf.getPage(i);
    const textContent = await page.getTextContent();
    const pageText = textContent.items
      .map((item: any) => item.str)
      .join(' ');
    if (pageText.trim()) {
      textParts.push(`[Page ${i}]\n${pageText}`);
    }
  }

  return textParts.join('\n\n');
}

/**
 * Get images for analysis from an UploadedResource.
 * Routes based on resource type.
 */
async function getImagesForAnalysis(
  resource: UploadedResource,
  originalFile?: File
): Promise<string[]> {
  switch (resource.type) {
    case 'image':
      // Image resources have base64 in content.images (from imageProcessor)
      return resource.content?.images || [];

    case 'pdf':
      // PDF needs page rendering - requires original file
      if (!originalFile) {
        throw new Error('Original file required for PDF analysis');
      }
      return extractPdfImages(originalFile);

    case 'docx':
      // DOCX has no visual rendering - AI relies on extracted text
      return [];

    default:
      return [];
  }
}

/**
 * Get text content for analysis from an UploadedResource.
 */
async function getTextForAnalysis(
  resource: UploadedResource,
  originalFile?: File
): Promise<string> {
  // DOCX and image resources have text in content.text (from processors)
  if (resource.content?.text) {
    return resource.content.text;
  }

  // PDF needs text extraction - requires original file
  if (resource.type === 'pdf' && originalFile) {
    return extractPdfText(originalFile);
  }

  return '';
}

/**
 * Analyze an uploaded document to detect structure and content.
 *
 * @param resource - The UploadedResource from upload service
 * @param provider - AI provider instance (Gemini or Claude)
 * @param originalFile - Original File object (required for PDF processing)
 * @returns Analysis result with detected type, elements, and UI hints
 */
export async function analyzeUploadedDocument(
  resource: UploadedResource,
  provider: AIProviderInterface,
  originalFile?: File
): Promise<AnalysisResult> {
  // Extract images and text for AI analysis
  const [images, text] = await Promise.all([
    getImagesForAnalysis(resource, originalFile),
    getTextForAnalysis(resource, originalFile)
  ]);

  // Run AI analysis
  const analysis = await provider.analyzeDocument(
    images,
    text,
    resource.type,
    resource.filename,
    resource.pageCount
  );

  // Determine if user should confirm document type
  // Show confirmation if:
  // - Confidence is not high
  // - Alternative types were suggested
  const needsTypeConfirmation =
    analysis.documentTypeConfidence !== 'high' ||
    (analysis.alternativeTypes && analysis.alternativeTypes.length > 0);

  return { analysis, needsTypeConfirmation };
}

/**
 * Update document type in analysis (when user overrides AI classification).
 * Returns new analysis with updated type.
 */
export function overrideDocumentType(
  analysis: DocumentAnalysis,
  newType: DocumentAnalysis['documentType']
): DocumentAnalysis {
  return {
    ...analysis,
    documentType: newType,
    documentTypeConfidence: 'high', // User confirmed
    alternativeTypes: undefined // Clear alternatives
  };
}
```
  </action>
  <verify>
    - TypeScript compiles: `cd "/Users/ricky/Documents/App_Projects/Education Apps/DEV - Cue" && npx tsc --noEmit`
    - Service exports correctly: grep "export async function analyzeUploadedDocument" services/documentAnalysis/documentAnalysisService.ts
    - Build succeeds: `cd "/Users/ricky/Documents/App_Projects/Education Apps/DEV - Cue" && npm run build`
  </verify>
  <done>
    - documentAnalysisService.ts created with analyzeUploadedDocument function
    - PDF image and text extraction implemented
    - overrideDocumentType helper for user type confirmation
    - AnalysisResult type includes needsTypeConfirmation flag
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. TypeScript compilation passes:
   ```bash
   cd "/Users/ricky/Documents/App_Projects/Education Apps/DEV - Cue" && npx tsc --noEmit
   ```

2. Build succeeds:
   ```bash
   cd "/Users/ricky/Documents/App_Projects/Education Apps/DEV - Cue" && npm run build
   ```

3. All new exports present:
   ```bash
   grep -l "DocumentAnalysis" types.ts services/aiProvider.ts services/documentAnalysis/*.ts
   grep -l "analyzeDocument" services/aiProvider.ts services/providers/*.ts
   grep -l "analyzeUploadedDocument" services/documentAnalysis/documentAnalysisService.ts
   ```
</verification>

<success_criteria>
- DocumentAnalysis and AnalyzedElement types defined and exported from types.ts
- analyzeDocument method added to AIProviderInterface
- GeminiProvider implements analyzeDocument with Gemini structured output (temperature: 0)
- ClaudeProvider implements analyzeDocument with Claude tool use pattern
- documentAnalysisService.ts exports analyzeUploadedDocument function
- PDF page rendering extracts images at scale 1.5 for AI analysis
- PDF text extraction supplements visual analysis
- Analysis returns needsTypeConfirmation boolean for UI flow
- TypeScript compiles without errors
- Build succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/44-ai-document-analysis/44-01-SUMMARY.md`
</output>
